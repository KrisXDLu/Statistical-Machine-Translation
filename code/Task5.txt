
Discussion :

Generally the bleu score increases with the training data size increase, 
it could be the result of the larger training size is more fit to the language.
Since our data size is still relatively small to the language size. Higher bleu score 
indicates better translation.  Larger data size makes our code understand the language better.
However, we didn't see a such significant difference when our tranining size changed from 15k
to 30k, this could because our model is too fit on the training data, and not as general anymore
on the testing data.

There is a lot of zeros in three gram possible because translating is much harder and our 
implementation is not as good as in terms of ordering and the correct translation.  
Also, three gram is harder to much since language is very complex and different ordering 
and difference choice of words in a sentence still could lead to the same meaning.

When I examin the two references, I find that they are very much similar to each other.
It is better to find more than one reference since there are many ways in translating 
the same language.


----------Evaluation START----------

### Evaluating AM model: AM0 ### 
Training size 1000:
BLEU_score with n:1
bleu: [0.23529411764705882, 0.3333333333333333, 0.5384615384615384, 0.35714285714285715, 0.38461538461538464, 0.5, 0.3076923076923077, 0.5, 0.24767939992862334, 0.3, 0.46153846153846156, 0.35714285714285715, 0.3, 0.5555555555555556, 0.39572488576635756, 0.30668147154310776, 0.4444444444444444, 0.3994650442174472, 0.23076923076923078, 0.5429024508215757, 0.625, 0.6363636363636364, 0.42857142857142855, 0.3888888888888889, 0.375]

BLEU_score with n:2
bleu: [0.12126781251816648, 0.2041241452319315, 0.29957234475763905, 0.16574838603294897, 0.17902871850985824, 0.408248290463863, 0.16012815380508713, 0.3779644730092272, 0.0, 0.0, 0.3396831102433787, 0.2344036154692477, 0.18257418583505536, 0.3131121455425747, 0.2912456299952812, 0.22649927752786161, 0.3333333333333333, 0.251324578876653, 0.1386750490563073, 0.3303999098220179, 0.4225771273642583, 0.504524979109513, 0.3144854510165755, 0.21389631597324932, 0.23145502494313785]

BLEU_score with n:3
bleu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.3466806371753174, 0.0, 0.0, 0.0, 0.0, 0.21890301363223727, 0.0, 0.0, 0.1829896873800057, 0.18768830180431176, 0.0, 0.25131581370971795, 0.0, 0.0, 0.0, 0.0, 0.304677894412465, 0.2019946918985375, 0.0, 0.0]




### Evaluating AM model: AM1 ### 
Training size 10000:
BLEU_score with n:1
bleu: [0.4117647058823529, 0.4444444444444444, 0.46153846153846156, 0.5714285714285714, 0.38461538461538464, 0.6, 0.38461538461538464, 0.625, 0.24767939992862334, 0.4, 0.6153846153846154, 0.5, 0.5, 0.5, 0.5276331810218101, 0.46002220731466165, 0.4444444444444444, 0.499331305271809, 0.3076923076923077, 0.5429024508215757, 0.75, 0.7272727272727273, 0.5, 0.4444444444444444, 0.375]

BLEU_score with n:2
bleu: [0.16042223697993696, 0.23570226039551584, 0.2773500981126146, 0.29649972666444047, 0.17902871850985824, 0.4472135954999579, 0.17902871850985824, 0.5175491695067657, 0.0, 0.21081851067789195, 0.3922322702763681, 0.2773500981126146, 0.23570226039551584, 0.2970442628930023, 0.3363014857561555, 0.33974891629179244, 0.3333333333333333, 0.28098942139235195, 0.16012815380508713, 0.3303999098220179, 0.5669467095138409, 0.6030226891555273, 0.3396831102433787, 0.28005601680560194, 0.23145502494313785]

BLEU_score with n:3
bleu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.36840314986403866, 0.0, 0.354745852992596, 0.0, 0.0, 0.2409339418591454, 0.0, 0.0, 0.1766746006576983, 0.20657770600880518, 0.21980706692931107, 0.25131581370971795, 0.0, 0.0, 0.0, 0.37697372056457695, 0.432332878165352, 0.2126451851414951, 0.16987257792186555, 0.0]




### Evaluating AM model: AM2 ### 
Training size 15000:
BLEU_score with n:1
bleu: [0.4117647058823529, 0.4444444444444444, 0.5384615384615384, 0.5, 0.3076923076923077, 0.6, 0.46153846153846156, 0.625, 0.24767939992862334, 0.4, 0.6153846153846154, 0.35714285714285715, 0.4, 0.5, 0.4616790333940838, 0.46002220731466165, 0.4444444444444444, 0.499331305271809, 0.3076923076923077, 0.5429024508215757, 0.75, 0.8181818181818182, 0.5, 0.4444444444444444, 0.375]

BLEU_score with n:2
bleu: [0.16042223697993696, 0.23570226039551584, 0.29957234475763905, 0.19611613513818404, 0.16012815380508713, 0.4472135954999579, 0.19611613513818404, 0.5175491695067657, 0.0, 0.21081851067789195, 0.3922322702763681, 0.2344036154692477, 0.21081851067789195, 0.2970442628930023, 0.31458123459064263, 0.33974891629179244, 0.3333333333333333, 0.28098942139235195, 0.16012815380508713, 0.3303999098220179, 0.5669467095138409, 0.7006490497453707, 0.3396831102433787, 0.28005601680560194, 0.23145502494313785]

BLEU_score with n:3
bleu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.36840314986403866, 0.0, 0.354745852992596, 0.0, 0.0, 0.2409339418591454, 0.0, 0.0, 0.1766746006576983, 0.19758446774491528, 0.21980706692931107, 0.25131581370971795, 0.0, 0.0, 0.0, 0.37697372056457695, 0.5469655075928689, 0.2126451851414951, 0.16987257792186555, 0.0]




### Evaluating AM model: AM3 ### 
Training size 30000:
BLEU_score with n:1
bleu: [0.4117647058823529, 0.4444444444444444, 0.5384615384615384, 0.5, 0.3076923076923077, 0.6, 0.46153846153846156, 0.625, 0.24767939992862334, 0.3, 0.6153846153846154, 0.35714285714285715, 0.5, 0.5, 0.39572488576635756, 0.46002220731466165, 0.4444444444444444, 0.499331305271809, 0.3076923076923077, 0.5429024508215757, 0.75, 0.8181818181818182, 0.5, 0.4444444444444444, 0.375]

BLEU_score with n:2
bleu: [0.16042223697993696, 0.23570226039551584, 0.29957234475763905, 0.19611613513818404, 0.16012815380508713, 0.4472135954999579, 0.19611613513818404, 0.5175491695067657, 0.0, 0.0, 0.3922322702763681, 0.2344036154692477, 0.23570226039551584, 0.2970442628930023, 0.2912456299952812, 0.33974891629179244, 0.3333333333333333, 0.28098942139235195, 0.16012815380508713, 0.3303999098220179, 0.5669467095138409, 0.7006490497453707, 0.3396831102433787, 0.28005601680560194, 0.23145502494313785]

BLEU_score with n:3
bleu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.36840314986403866, 0.0, 0.354745852992596, 0.0, 0.0, 0.2409339418591454, 0.0, 0.0, 0.1766746006576983, 0.18768830180431176, 0.21980706692931107, 0.25131581370971795, 0.0, 0.0, 0.0, 0.37697372056457695, 0.5469655075928689, 0.2126451851414951, 0.16987257792186555, 0.0]



----------Evaluation END----------
